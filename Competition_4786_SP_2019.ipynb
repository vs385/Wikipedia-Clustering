{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "# Welcome to the Wikipedia Clustering Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "For this competition you are given 11039 articles from wikipedia and you need to cluster them into 4 clusters such that the clusters accurately coincide with the 4 categories the articles belong to which are \"actor\", \"movie\", \"Math\" or \"Mathematician\". \n",
    "\n",
    "You are given information about the articles in two forms. \n",
    "\n",
    "1. First, all the text of the articles are given in file:  \"raw_data.txt\". This file has one line for each articles and each line has all the text of the corresponding article. To make your life easier, I have written a code that extracts the lexicon from these articles and then extract the bag of words feature for each articles. These code snippets are provided in the function definition of function Competition_solution() in commented format. Once the bag of words feature is extracted, I have saved the resultant data matrix in sparse matrix format in file \"data.npz\". You have the freedom to redo or edit my code for the bag of words feature extraction or write your own code to do whatever feature extraction you might want to use. However I suggest that at least to begin with, start with just loading the data matrix from the file \"data.npz\" which in current code is not commented and is automatically loaded in variable X for you in sparse matrix format.\n",
    "\n",
    "2. Second, you are given a (directed) graph given in file \"graph.csv\" that contains the graph as a matrix with 174309 rows and two columns. Each line of the matrix lists an edge in the graph. For instance, the row \"100, 200\" means there is a hyperlink from wikipedia page of article # \"100\" linking it to article # \"200\".\n",
    "\n",
    "Using the text and the hyperlink information amongst the wikipedia articles, your goal is to cluster the articles into 4 categories. You can use any library you need and write your own method. You can work in groups of size at most 4. \n",
    "\n",
    "Your final prediction should be returned by your function in variable \"prediction\" which is a matrix of size $11039 \\times 1$ with entries being one of 0, 1, 2, or 3. \n",
    "\n",
    "We will evaluate how well your clustering predicts the actual categories of the articles and return to you accuracy in percentage. Higher the better.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "from zipfile import ZipFile\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn import random_projection\n",
    "from sklearn import decomposition as decomp\n",
    "from sklearn import manifold\n",
    "from sklearn import mixture\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sp.load_npz('./X.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G = np.loadtxt('./G.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Adj = sp.load_npz('./Adj.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = X.shape[0]\n",
    "Gint = G.astype(np.int)\n",
    "Adj_sym = np.zeros((n,n))\n",
    "Adj_sym[Gint[:, 0], Gint[:, 1]] = 1\n",
    "Adj_sym[Gint[:, 1], Gint[:, 0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svd_projector = decomp.TruncatedSVD(\n",
    "    n_components = 1000\n",
    ")\n",
    "\n",
    "pca_projector = decomp.PCA(\n",
    "    n_components = 0.95, copy=False\n",
    ")\n",
    "\n",
    "kpca_projector = decomp.KernelPCA(\n",
    "    n_components=5000, kernel=\"rbf\",\n",
    "    copy_X=False\n",
    ")\n",
    "\n",
    "random_projector = random_projection.SparseRandomProjection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_predictor = cluster.KMeans(\n",
    "    n_clusters = 4\n",
    ")\n",
    "\n",
    "link_predictor = cluster.AgglomerativeClustering(\n",
    "    n_clusters = 4, affinity='euclidean',\n",
    "    linkage='ward'\n",
    ")\n",
    "\n",
    "spectral_predictor = cluster.SpectralClustering(\n",
    "    n_clusters=4, affinity=\"precomputed\"\n",
    ")\n",
    "\n",
    "mix_predictor = mixture.GaussianMixture(\n",
    "    n_components=4\n",
    ")\n",
    "\n",
    "guided_link_predictor = cluster.AgglomerativeClustering(\n",
    "    n_clusters = 4, connectivity = Adj\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def Competition_solution():\n",
    "\n",
    "# Now we load the graph and the data matrix (saved as a sparse matrix)\n",
    "#     G = np.loadtxt('./G.npy')\n",
    "#     X = sp.load_npz('./X.npz')\n",
    "#     Adj = sp.load_npz('./Adj.npz')\n",
    "    \n",
    "#     n = X.shape[0]\n",
    "\n",
    "# Fill in your code below to do whatever you want so it fills in predictions for the \n",
    "# n articles to be one of the four classes {0,1,2,3}. Currently I have set it to \n",
    "# randomly pick labels for the articles. \n",
    "# FYI \"0: \", \"1: \", \"2: \" and \"3: \"\n",
    "\n",
    "    print(\"Projecting\")\n",
    "\n",
    "#     XPrime = svd_projector.fit_transform(X)\n",
    "    \n",
    "    print(\"Predicting\")\n",
    "\n",
    "    prediction = spectral_predictor.fit_predict(Adj_sym)\n",
    "    \n",
    "    return prediction\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting\n",
      "Predicting\n"
     ]
    }
   ],
   "source": [
    "prediction = Competition_solution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ward clustering w/ pca 2000: 42%\n",
    "\n",
    "Ward clustering w/ kpca rbf 2000: 42%\n",
    "\n",
    "Ward clustering and random projection: 47%\n",
    "\n",
    "Spectral Clustering on G adjacency (average symmetry): 93.9%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "source": [
    "The following code will generate a `result.npy` file, which contains your final prediction that we will grade upon. If you want to work offline instead, you can save your work as below with the title of `result.npy` and utilize the upload feature on Vocareum for grading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "np.save('result.npy', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 0, 3, 3, 0, 3, 0, 0, 3, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0, 3, 1,\n",
       "       2, 0, 0, 0, 3, 2, 0, 0, 3, 0, 0, 0, 3, 3, 1, 0, 0, 0, 0, 1, 3, 0,\n",
       "       0, 2, 3, 0, 0, 0, 0, 3, 1, 3, 0, 0, 3, 2, 3, 0, 2, 0, 0, 0, 3, 0,\n",
       "       3, 0, 0, 0, 0, 0, 0, 3, 0, 0, 3, 3, 2, 0, 0, 0, 3, 3, 3, 0, 3, 0,\n",
       "       0, 0, 2, 3, 3, 3, 1, 0, 0, 2, 0, 3, 3, 3, 0, 0, 0, 0, 3, 3, 0, 1,\n",
       "       3, 0, 3, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 3, 0, 1, 3, 1, 0, 0,\n",
       "       0, 0, 2, 0, 1, 0, 2, 0, 1, 0, 3, 3, 0, 0, 0, 0, 2, 0, 3, 0, 0, 0,\n",
       "       3, 3, 0, 3, 3, 0, 3, 3, 0, 3, 0, 0, 3, 3, 3, 2, 0, 2, 3, 2, 3, 0,\n",
       "       0, 0, 0, 2, 0, 3, 3, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 3,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 3, 2, 3, 0, 3, 3, 3,\n",
       "       0, 3, 1, 3, 3, 0, 0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 2, 3, 0, 2,\n",
       "       3, 1, 3, 3, 0, 0, 3, 3, 2, 3, 3, 0, 3, 0, 0, 3, 0, 3, 0, 0, 0, 0,\n",
       "       0, 3, 0, 0, 0, 0, 0, 3, 1, 0, 3, 0, 1, 3, 0, 0, 3, 0, 3, 0, 3, 3,\n",
       "       3, 3, 3, 0, 0, 3, 3, 1, 0, 2, 0, 0, 0, 3, 3, 2, 0, 3, 3, 3, 2, 0,\n",
       "       3, 1, 0, 1, 0, 0, 0, 0, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 0, 3, 3, 0,\n",
       "       3, 0, 0, 0, 2, 0, 3, 0, 3, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0,\n",
       "       0, 0, 3, 3, 3, 3, 1, 0, 0, 3, 0, 3, 3, 0, 0, 0, 0, 3, 3, 3, 0, 0,\n",
       "       0, 0, 0, 2, 0, 0, 3, 0, 3, 1, 3, 3, 3, 1, 0, 0, 0, 0, 0, 0, 3, 0,\n",
       "       0, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 3, 1, 3, 3, 0, 0, 0, 0, 0, 0, 3,\n",
       "       3, 0, 3, 3, 3, 3, 0, 3, 0, 3, 0, 3, 0, 3, 3, 0, 0, 0, 0, 2, 0, 3,\n",
       "       3, 0, 0, 3, 0, 3, 0, 0, 0, 3, 2, 2, 0, 0, 0, 3, 2, 0, 0, 3, 0, 3,\n",
       "       0, 0, 3, 3, 0, 3, 0, 3, 1, 3, 0, 0, 3, 3, 3, 0, 3, 0, 0, 3, 0, 2,\n",
       "       3, 3, 3, 3, 3, 0, 0, 3, 0, 3, 0, 3, 3, 0, 3, 3, 0, 3, 0, 3, 0, 0,\n",
       "       3, 3, 0, 0, 3, 3, 0, 0, 1, 3, 2, 3, 3, 0, 3, 0, 0, 0, 1, 3, 0, 0,\n",
       "       3, 0, 3, 0, 0, 3, 1, 0, 3, 0, 0, 0, 3, 3, 3, 3, 0, 3, 0, 3, 0, 0,\n",
       "       0, 3, 3, 0, 3, 3, 0, 0, 2, 3, 3, 3, 0, 0, 3, 0, 0, 0, 3, 1, 0, 0,\n",
       "       3, 0, 3, 0, 0, 3, 0, 3, 1, 0, 3, 3, 0, 1, 0, 1, 0, 3, 0, 3, 3, 1,\n",
       "       3, 0, 3, 0, 3, 0, 0, 1, 3, 0, 3, 1, 0, 3, 0, 3, 0, 3, 0, 0, 3, 3,\n",
       "       0, 3, 1, 0, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 1, 0, 3, 2,\n",
       "       3, 0, 3, 3, 3, 0, 0, 3, 3, 0, 0, 0, 3, 3, 0, 0, 0, 0, 3, 0, 3, 3,\n",
       "       3, 0, 0, 2, 0, 2, 3, 0, 3, 3, 3, 0, 0, 3, 0, 3, 0, 1, 0, 0, 0, 3,\n",
       "       2, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 1, 0, 3, 0, 0, 0, 3, 3, 3, 3, 3,\n",
       "       3, 3, 0, 3, 0, 3, 0, 0, 0, 2, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 2, 0, 0, 3, 3, 0, 3, 3, 3, 3, 3, 0, 0, 3, 0, 0,\n",
       "       3, 3, 0, 2, 0, 2, 0, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0, 3,\n",
       "       3, 3, 0, 3, 3, 0, 0, 0, 3, 0, 3, 3, 0, 0, 3, 3, 0, 0, 2, 3, 0, 0,\n",
       "       3, 2, 0, 3, 0, 0, 2, 0, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 0,\n",
       "       3, 0, 0, 0, 3, 3, 0, 0, 3, 0, 2, 3, 3, 0, 0, 0, 0, 3, 3, 0, 3, 3,\n",
       "       0, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       3, 0, 3, 3, 3, 3, 0, 3, 3, 3, 0, 3, 3, 3, 3, 0, 2, 0, 3, 0, 0, 0,\n",
       "       0, 3, 3, 3, 3, 0, 0, 2, 1, 3, 3, 3, 0, 3, 3, 3, 3, 0, 0, 0, 3, 0,\n",
       "       0, 0, 0, 1, 0, 3, 0, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 0, 0, 3, 3, 3,\n",
       "       3, 3, 3, 0, 3, 2, 3, 0, 0, 3, 0, 0, 3, 3, 3, 3, 2, 3, 3, 3, 0, 0,\n",
       "       2, 0, 0, 0, 0, 3, 0, 3, 3, 3, 3, 1, 0, 0, 0, 3, 3, 0, 3, 0, 0, 0,\n",
       "       3, 0, 0, 3, 1, 3, 3, 0, 0, 3, 3, 3, 0, 0, 0, 0, 3, 0, 0, 0, 3, 0,\n",
       "       3, 0, 0, 3, 0, 3, 3, 0, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.6]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
